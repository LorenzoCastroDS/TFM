{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20631, 19)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_train_1 = pd.read_csv('/home/dsc/Downloads/CMAPSSData/train_FD001.txt', sep=\" \", header=None)\n",
    "\n",
    "list_units_1 = 3\n",
    "operational_list = []\n",
    "for n in range(1,list_units_1+1):\n",
    "    operational = \"operarional_setting_\" + str(n)\n",
    "    operational_list.append(operational)\n",
    "\n",
    "list_units_2 = 23\n",
    "sensor_measurement_list = []\n",
    "for n in range(1,list_units_2+1):\n",
    "    sensor = \"sensor_measurement_\" + str(n)\n",
    "    sensor_measurement_list.append(sensor)\n",
    "df_train_1.columns = [\"ID\", \"Cycle\"] + operational_list + sensor_measurement_list\n",
    "\n",
    "df_train_1 = df_train_1.dropna(axis=1)\n",
    "\n",
    "max_cycle_dataset_1 = df_train_1.groupby([\"ID\"])[\"Cycle\"].max().reset_index()\n",
    "max_cycle_dataset_1 = max_cycle_dataset_1.rename(columns={\"Cycle\":\"Max_cycle\"})\n",
    "df_train_1 = df_train_1.merge(max_cycle_dataset_1, how=\"inner\", on=\"ID\")\n",
    "df_train_1[\"RUL\"] = df_train_1[\"Max_cycle\"] - df_train_1[\"Cycle\"]\n",
    "df_train_1 = df_train_1.drop([\"Max_cycle\"],axis=1)\n",
    "\n",
    "df_train_1.drop(columns=\"operarional_setting_3\",axis=1, inplace=True)\n",
    "columns_to_delete = ['sensor_measurement_1', 'sensor_measurement_5', 'sensor_measurement_6', 'sensor_measurement_10', 'sensor_measurement_16', 'sensor_measurement_18', 'sensor_measurement_19']\n",
    "df_train_1.drop(columns=columns_to_delete, axis=1, inplace=True)\n",
    "\n",
    "#df_train_1.drop(columns=\"sensor_measurement_14\", axis=1, inplace=True)\n",
    "\n",
    "df_train_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096, 18)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_1 = pd.read_csv('/home/dsc/Downloads/CMAPSSData/test_FD001.txt', sep=\" \", header=None)\n",
    "list_units_1 = 3\n",
    "operational_list = []\n",
    "for n in range(1,list_units_1+1):\n",
    "    operational = \"operarional_setting_\" + str(n)\n",
    "    operational_list.append(operational)\n",
    "list_units_2 = 23\n",
    "sensor_measurement_list = []\n",
    "for n in range(1,list_units_2+1):\n",
    "    sensor = \"sensor_measurement_\" + str(n)\n",
    "    sensor_measurement_list.append(sensor)\n",
    "\n",
    "df_test_1.columns = [\"ID\", \"Cycle\"] + operational_list + sensor_measurement_list\n",
    "df_test_1 = df_test_1.dropna(axis=1)\n",
    "df_test_1.drop(columns=\"operarional_setting_3\",axis=1, inplace=True)\n",
    "df_test_1.drop(columns=columns_to_delete, axis=1, inplace=True)\n",
    "#df_test_1.drop(columns=\"sensor_measurement_14\", axis=1, inplace=True)\n",
    "\n",
    "df_test_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rul_1 = pd.read_csv('/home/dsc/Downloads/CMAPSSData/RUL_FD001.txt', sep=\" \", header=None)\n",
    "\n",
    "\n",
    "df_rul_1.dropna(axis=1,inplace=True)\n",
    "#df_rul_1[\"ID\"] = np.arange(1, 101)\n",
    "df_rul_1.columns = [\"RUL\"]\n",
    "#df_rul_1 = df_rul_1[[\"ID\",\"RUL\"]]\n",
    "df_rul_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train columns:  Index(['operarional_setting_1', 'operarional_setting_2',\n",
      "       'sensor_measurement_2', 'sensor_measurement_3', 'sensor_measurement_4',\n",
      "       'sensor_measurement_7', 'sensor_measurement_8', 'sensor_measurement_9',\n",
      "       'sensor_measurement_11', 'sensor_measurement_12',\n",
      "       'sensor_measurement_13', 'sensor_measurement_14',\n",
      "       'sensor_measurement_15', 'sensor_measurement_17',\n",
      "       'sensor_measurement_20', 'sensor_measurement_21'],\n",
      "      dtype='object') \n",
      " X_test columns:  Index(['operarional_setting_1', 'operarional_setting_2',\n",
      "       'sensor_measurement_2', 'sensor_measurement_3', 'sensor_measurement_4',\n",
      "       'sensor_measurement_7', 'sensor_measurement_8', 'sensor_measurement_9',\n",
      "       'sensor_measurement_11', 'sensor_measurement_12',\n",
      "       'sensor_measurement_13', 'sensor_measurement_14',\n",
      "       'sensor_measurement_15', 'sensor_measurement_17',\n",
      "       'sensor_measurement_20', 'sensor_measurement_21'],\n",
      "      dtype='object') \n",
      " (20631,)\n"
     ]
    }
   ],
   "source": [
    "labels_to_drop = [\"ID\",\"Cycle\"]\n",
    "X_train1 = df_train_1.drop(labels_to_drop+[\"RUL\"], axis=1)\n",
    "y_train1 = df_train_1[\"RUL\"]\n",
    "\n",
    "X_test1 = df_test_1.groupby(\"ID\").last().reset_index().drop(labels_to_drop, axis=1)\n",
    "y_test1 = df_rul_1\n",
    "print(\"X_train columns: \", X_train1.columns, \"\\n\",\n",
    "     \"X_test columns: \", X_test1.columns, \"\\n\",\n",
    "     y_train1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20631, 16), (20631,), (100, 16), (100, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1.shape, y_train1.shape, X_test1.shape, df_rul_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    RUL\n",
       "0   112\n",
       "1    98\n",
       "2    69\n",
       "3    82\n",
       "4    91\n",
       "..  ...\n",
       "95  137\n",
       "96   82\n",
       "97   59\n",
       "98  117\n",
       "99   20\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rul_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                              MODELS AS IT IS -------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN \n",
      " MAE:  34.11381828711524 \n",
      " R2 score:  0.5794932912981662\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "preds_train1 = lr.predict(X_train1)\n",
    "print(\"TRAIN\", \"\\n\",\n",
    "      \"MAE: \",mean_absolute_error(preds_train1, y_train1), \"\\n\",\n",
    "      \"R2 score: \", r2_score(y_train1, preds_train1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN \n",
      " MAE:  25.593806249895135 \n",
      " R2 score:  0.4054344040525887\n"
     ]
    }
   ],
   "source": [
    "preds_test1 = lr.predict(X_test1)\n",
    "print(\"TRAIN\", \"\\n\",\n",
    "      \"MAE: \",mean_absolute_error(preds_test1, df_rul_1), \"\\n\",\n",
    "      \"R2 score: \", r2_score(df_rul_1, preds_test1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN = 0.579\n",
    "#### TEST = 0.405"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM FOREST REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)]\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=RandomForestRegressor(),\n",
       "                   param_distributions={'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110],\n",
       "                                        'n_estimators': [10, 20, 30, 40, 50, 60,\n",
       "                                                         70, 80, 90, 100]},\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = RandomForestRegressor()\n",
    "rf_random = RandomizedSearchCV(estimator=regr, param_distributions=random_grid, random_state=42)\n",
    "rf_random.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 50, 'max_depth': 10}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = list(rf_random.best_params_.values())[0]\n",
    "max_depth = list(rf_random.best_params_.values())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=10, n_estimators=50)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_regr = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth)\n",
    "hyper_regr.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST TRAIN SCORES - - - -  \n",
      " MAE:  25.448241817037026 \n",
      " R2 score:  0.7212645194371912\n"
     ]
    }
   ],
   "source": [
    "rul_train_pred_rf = hyper_regr.predict(X_train1)\n",
    "print(\"RANDOM FOREST TRAIN SCORES - - - - \", \"\\n\",\n",
    "    \"MAE: \", mean_absolute_error(y_train1, rul_train_pred_rf), \"\\n\",\n",
    "      \"R2 score: \", r2_score(y_train1, rul_train_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST TEST SCORES - - - -  \n",
      " MAE:  24.213833455593882 \n",
      " R2 score:  0.3938775818528696\n"
     ]
    }
   ],
   "source": [
    "rul_test_pred_rf = hyper_regr.predict(X_test1)\n",
    "print(\"RANDOM FOREST TEST SCORES - - - - \", \"\\n\",\n",
    "    \"MAE: \", mean_absolute_error(df_rul_1, rul_test_pred_rf), \"\\n\",\n",
    "      \"R2 score: \", r2_score(df_rul_1, rul_test_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN = 0.721\n",
    "#### TEST = 0.387"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = df_train_1.drop(labels_to_drop+[\"RUL\"], axis=1)\n",
    "y_train1 = df_train_1[\"RUL\"]\n",
    "\n",
    "X_test1 = df_test_1.groupby(\"ID\").last().reset_index().drop(labels_to_drop, axis=1)\n",
    "y_test1 = df_rul_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR(kernel=\"linear\")\n",
    "svr.fit(X_train1, y_train1)\n",
    "preds_train_svr = svr.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR TRAIN SCORES - - - -  \n",
      " MAE:  41.08592612483098 \n",
      " R2 score:  0.4277772082827639\n"
     ]
    }
   ],
   "source": [
    "preds_train_svr = svr.predict(X_train1)\n",
    "print(\"SVR TRAIN SCORES - - - - \", \"\\n\",\n",
    "    \"MAE: \", mean_absolute_error(y_train1, preds_train_svr), \"\\n\",\n",
    "      \"R2 score: \", r2_score(y_train1, preds_train_svr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR TEST SCORES - - - -  \n",
      " MAE:  35.12016117707506 \n",
      " R2 score:  0.2231324732734803\n"
     ]
    }
   ],
   "source": [
    "preds_test_svr = svr.predict(X_test1)\n",
    "print(\"SVR TEST SCORES - - - - \", \"\\n\",\n",
    "    \"MAE: \", mean_absolute_error(preds_test_svr, y_test1), \"\\n\",\n",
    "      \"R2 score: \", r2_score(preds_test_svr, y_test1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN = 0.4277\n",
    "#### TEST = 0.2231"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train1 = df_train_1.drop(labels_to_drop+[\"RUL\"], axis=1)\n",
    "y_train1 = df_train_1[\"RUL\"]\n",
    "\n",
    "X_test1 = df_test_1.groupby(\"ID\").last().reset_index().drop(labels_to_drop, axis=1)\n",
    "y_test1 = df_rul_1\n",
    "\n",
    "scaler.fit(X_train1)\n",
    "X_train_scal = scaler.transform(X_train1)\n",
    "X_test_scal = scaler.transform(X_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression (+ minMaxScal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scal, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN \n",
      " MAE:  34.113818287114796 \n",
      " R2 score:  0.5794932912981678\n"
     ]
    }
   ],
   "source": [
    "preds_train1 = lr.predict(X_train_scal)\n",
    "print(\"TRAIN\", \"\\n\",\n",
    "      \"MAE: \",mean_absolute_error(y_train1, preds_train1), \"\\n\",\n",
    "      \"R2 score: \", r2_score(y_train1, preds_train1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN \n",
      " MAE:  25.593806249892133 \n",
      " R2 score:  0.40543440405265174\n"
     ]
    }
   ],
   "source": [
    "preds_test1 = lr.predict(X_test_scal)\n",
    "print(\"TRAIN\", \"\\n\",\n",
    "      \"MAE: \",mean_absolute_error(y_test1, preds_test1), \"\\n\",\n",
    "      \"R2 score: \", r2_score(y_test1, preds_test1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN = 0.579\n",
    "#### TEST = 0.405"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor (+ minMaxScal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train1 = df_train_1.drop(labels_to_drop+[\"RUL\"], axis=1)\n",
    "y_train1 = df_train_1[\"RUL\"]\n",
    "\n",
    "X_test1 = df_test_1.groupby(\"ID\").last().reset_index().drop(labels_to_drop, axis=1)\n",
    "y_test1 = df_rul_1\n",
    "\n",
    "scaler.fit(X_train1)\n",
    "X_train_scal = scaler.transform(X_train1)\n",
    "X_test_scal = scaler.transform(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-66d9a685f6ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mregr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrf_random\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrf_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1527\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1528\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m         evaluate_candidates(ParameterSampler(\n\u001b[0m\u001b[1;32m   1530\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m             random_state=self.random_state))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    864\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m    387\u001b[0m                              \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'threads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    864\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                                         indices=indices)\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1240\u001b[0m         \"\"\"\n\u001b[1;32m   1241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1243\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "regr = RandomForestRegressor()\n",
    "rf_random = RandomizedSearchCV(estimator=regr, param_distributions=random_grid, random_state=42)\n",
    "rf_random.fit(X_train_scal, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = list(rf_random.best_params_.values())[0]\n",
    "max_depth = list(rf_random.best_params_.values())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_regr = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth)\n",
    "hyper_regr.fit(X_train_scal, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rul_train_pred_rf = hyper_regr.predict(X_train_scal)\n",
    "print(\"RANDOM FOREST TRAIN SCORES - - - - \", \"\\n\",\n",
    "    \"MAE: \", mean_absolute_error(y_train1, rul_train_pred_rf), \"\\n\",\n",
    "      \"R2 score: \", r2_score(y_train1, rul_train_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rul_test_pred_rf = hyper_regr.predict(X_test_scal)\n",
    "print(\"RANDOM FOREST TEST SCORES - - - - \", \"\\n\",\n",
    "    \"MAE: \", mean_absolute_error(df_rul_1, rul_test_pred_rf), \"\\n\",\n",
    "      \"R2 score: \", r2_score(df_rul_1, rul_test_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN = 0.579\n",
    "#### TEST = 0.405"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR (+ minMaxScal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train1 = df_train_1.drop(labels_to_drop+[\"RUL\"], axis=1)\n",
    "y_train1 = df_train_1[\"RUL\"]\n",
    "\n",
    "X_test1 = df_test_1.groupby(\"ID\").last().reset_index().drop(labels_to_drop, axis=1)\n",
    "y_test1 = df_rul_1\n",
    "\n",
    "scaler.fit(X_train1)\n",
    "X_train_scal = scaler.transform(X_train1)\n",
    "X_test_scal = scaler.transform(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR(kernel=\"linear\")\n",
    "svr.fit(X_train_scal, y_train1)\n",
    "preds_train_svr = svr.predict(X_train_scal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train_svr = svr.predict(X_train_scal)\n",
    "print(\"SVR + minMaxScal TRAIN SCORES - - - - \", \"\\n\",\n",
    "    \"MAE: \", mean_absolute_error(y_train1, preds_train_svr), \"\\n\",\n",
    "      \"R2 score: \", r2_score(y_train1, preds_train_svr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test_svr = svr.predict(X_test_scal)\n",
    "print(\"SVR + minMaxScal TEST SCORES - - - - \", \"\\n\",\n",
    "    \"MAE: \", mean_absolute_error(y_test1, preds_test_svr), \"\\n\",\n",
    "      \"R2 score: \", r2_score(y_test1, preds_test_svr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN = 0.5609\n",
    "#### TEST = 0.5984"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOP FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_train_1[df_train_1[\"ID\"]==1]\n",
    "x = df_1[\"Cycle\"].values.reshape(-1,1)\n",
    "\n",
    "cols = df_1.columns[2:-1]\n",
    "fig, axes = plt.subplots(len(cols), 1, figsize=(10,35))\n",
    "slopes = []\n",
    "for col, ax in zip(cols, axes):\n",
    "    linear = LinearRegression()\n",
    "    y = df_1[col].values.reshape(-1,1)\n",
    "    linear.fit(x,y)\n",
    "    preds = linear.predict(x)\n",
    "    ax.plot(x,y, label=col)\n",
    "    ax.plot(x,preds,\"g\",label='trend')\n",
    "    ax.legend(loc=2)\n",
    "    slope = linear.coef_\n",
    "    slopes.append(slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes_df = pd.DataFrame({\"columns\": cols, \"slope\":slopes})\n",
    "slopes_df[\"slope\"] = slopes_df[\"slope\"].apply(lambda x: abs(x))\n",
    "slopes_df = slopes_df.sort_values(\"slope\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression (+TopFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns = slopes_df[\"columns\"].values.tolist()\n",
    "column=[]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for col in columns:\n",
    "    column.append(col)\n",
    "    \n",
    "    df = df_train_1[[\"ID\",\"Cycle\"]+column]\n",
    "    X_train = df.drop(columns=[\"ID\",\"Cycle\"], axis=1)\n",
    "    \n",
    "    y_train = df_train_1[\"RUL\"]\n",
    "    df_test = df_test_1[[\"ID\", \"Cycle\"]+column]\n",
    "    df_test_red = df_test.groupby(\"ID\").last().reset_index()\n",
    "    X_test = df_test_red.drop(columns=[\"ID\",\"Cycle\"], axis=1)\n",
    "    y_test = df_rul_1\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    preds_train = lr.predict(X_train)\n",
    "    r2_tr = r2_score(y_train, preds_train)\n",
    "    train_scores.append(r2_tr)\n",
    "    print(\" TRAIN SCORE WITH {} top features: \".format(len(column)), r2_score(y_train, preds_train))\n",
    "    \n",
    "    preds_test = lr.predict(X_test)\n",
    "    r2_ts = r2_score(y_test, preds_test)\n",
    "    test_scores.append(r2_ts)\n",
    "    print(\" TEST SCORE WITH {} top features: \".format(len(column)), r2_score(y_test, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(range(0,len(column)),train_scores,label=\"train scores\")\n",
    "plt.plot(range(0,len(column)), test_scores, label=\"test scores\")\n",
    "plt.legend()\n",
    "mx_test = max(test_scores)\n",
    "mx_idx = test_scores.index(mx_test)\n",
    "train_mx_test = train_scores[mx_idx]\n",
    "print(\"LINEAR REGRESSION Train Score from max Test Score: \", train_mx_test, \"\\n\",\n",
    "      \"Max Test Score: \", mx_test, \"\\n\",\n",
    "     \"Achieved with {} features out of 15\".format(mx_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN = 0.5494\n",
    "#### TEST = 0.4087"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RanfdomForestRegressor (+TopFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = slopes_df[\"columns\"].values.tolist()\n",
    "column=[]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for col in columns:\n",
    "    column.append(col)\n",
    "    \n",
    "    df = df_train_1[[\"ID\",\"Cycle\"]+column]\n",
    "    X_train = df.drop(columns=[\"ID\",\"Cycle\"], axis=1)\n",
    "    y_train = df_train_1[\"RUL\"]\n",
    "    df_test = df_test_1[[\"ID\", \"Cycle\"]+column]\n",
    "    df_test_red = df_test.groupby(\"ID\").last().reset_index()\n",
    "    X_test = df_test_red.drop(columns=[\"ID\",\"Cycle\"], axis=1)\n",
    "    y_test = df_rul_1\n",
    "    \n",
    "    \n",
    "    regr = RandomForestRegressor()\n",
    "    rf_random = RandomizedSearchCV(estimator=regr, param_distributions=random_grid, random_state=42)\n",
    "    rf_random.fit(X_train, y_train1)\n",
    "    \n",
    "    n_estimators = list(rf_random.best_params_.values())[0]\n",
    "    max_depth = list(rf_random.best_params_.values())[1]\n",
    "    \n",
    "    hyper_regr = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth)\n",
    "    hyper_regr.fit(X_train, y_train)\n",
    "    \n",
    "    rul_train_pred_rf = hyper_regr.predict(X_train)\n",
    "    r2_tr = r2_score(y_train, rul_train_pred_rf)\n",
    "    train_scores.append(r2_tr)\n",
    "    print(\" TRAIN SCORE WITH {} top features: \".format(len(column)), r2_score(y_train, rul_train_pred_rf))\n",
    "    \n",
    "    rul_test_pred_rf = hyper_regr.predict(X_test)\n",
    "    r2_ts = r2_score(y_test, rul_test_pred_rf)\n",
    "    test_scores.append(r2_ts)\n",
    "    print(\" TEST SCORE WITH {} top features: \".format(len(column)), r2_score(y_test, rul_test_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(range(0,len(column)),train_scores,label=\"train scores\")\n",
    "plt.plot(range(0,len(column)), test_scores, label=\"test scores\")\n",
    "plt.legend()\n",
    "mx_test = max(test_scores)\n",
    "mx_idx = test_scores.index(mx_test)\n",
    "train_mx_test = train_scores[mx_idx]\n",
    "print(\"RANDOMFOREST REGRESSOR Train Score from max Test Score: \", train_mx_test, \"\\n\",\n",
    "      \"Max Test Score: \", mx_test, \"\\n\",\n",
    "     \"Achieved with {} features out of 15\".format(mx_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN = 0.5494\n",
    "#### TEST = 0.4087"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR (+TopFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = slopes_df[\"columns\"].values.tolist()\n",
    "column=[]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for col in columns:\n",
    "    column.append(col)\n",
    "    \n",
    "    df = df_train_1[[\"ID\",\"Cycle\"]+column]\n",
    "    X_train = df.drop(columns=[\"ID\",\"Cycle\"], axis=1)\n",
    "    \n",
    "    y_train = df_train_1[\"RUL\"]\n",
    "    df_test = df_test_1[[\"ID\", \"Cycle\"]+column]\n",
    "    df_test_red = df_test.groupby(\"ID\").last().reset_index()\n",
    "    X_test = df_test_red.drop(columns=[\"ID\",\"Cycle\"], axis=1)\n",
    "    y_test = df_rul_1\n",
    "    \n",
    "    svr = SVR(kernel=\"linear\")\n",
    "    svr.fit(X_train, y_train)\n",
    "    preds_train = svr.predict(X_train)\n",
    "    r2_tr = r2_score(y_train, preds_train)\n",
    "    train_scores.append(r2_tr)\n",
    "    print(\" TRAIN SCORE WITH {} top features: \".format(len(column)), r2_score(y_train, preds_train))\n",
    "    \n",
    "    preds_test = svr.predict(X_test)\n",
    "    r2_ts = r2_score(y_test, preds_test)\n",
    "    test_scores.append(r2_ts)\n",
    "    print(\" TEST SCORE WITH {} top features: \".format(len(column)), r2_score(y_test, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,len(column)),train_scores,label=\"train scores\")\n",
    "plt.plot(range(0,len(column)), test_scores, label=\"test scores\")\n",
    "plt.legend()\n",
    "mx_test = max(test_scores)\n",
    "mx_idx = test_scores.index(mx_test)\n",
    "train_mx_test = train_scores[mx_idx]\n",
    "print(\"SVR Train Score from max Test Score: \", train_mx_test, \"\\n\",\n",
    "      \"Max Test Score: \", mx_test, \"\\n\",\n",
    "     \"Achieved with {} features out of 15\".format(mx_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN = 0.5494\n",
    "#### TEST = 0.4087"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# y_CLIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearRegression (+y_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips = np.arange(100,170,5).tolist()\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for clip in clips:\n",
    "    X_train = df_train_1.drop(columns=[\"ID\",\"Cycle\",\"RUL\",\"operarional_setting_1\",\"operarional_setting_2\"], axis=1)\n",
    "    y_train_clip = df_train_1[\"RUL\"].clip(upper=clip)\n",
    "\n",
    "    df_test_1_red = df_test_1.groupby(\"ID\").last().reset_index()\n",
    "    X_test = df_test_1_red.drop(columns=[\"ID\",\"Cycle\",\"operarional_setting_1\",\"operarional_setting_2\"], axis=1)\n",
    "    y_test = df_rul_1\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train_clip)\n",
    "    preds_train = lr.predict(X_train)\n",
    "    r2_tr = r2_score(y_train_clip, preds_train)\n",
    "    train_scores.append(r2_tr)\n",
    "    print(\" TRAIN SCORE WITH {} upper clipped RUL: \".format(clip), r2_score(y_train_clip, preds_train))\n",
    "    \n",
    "    preds_test = lr.predict(X_test)\n",
    "    r2_ts = r2_score(y_test, preds_test)\n",
    "    test_scores.append(r2_ts)\n",
    "    print(\" TEST SCORE WITH {} upper clipped RUL: \".format(clip), r2_score(y_test, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,len(column)),train_scores,label=\"train scores\")\n",
    "plt.plot(range(0,len(column)), test_scores, label=\"test scores\")\n",
    "plt.legend()\n",
    "mx_test = max(test_scores)\n",
    "mx_idx = test_scores.index(mx_test)\n",
    "train_mx_test = train_scores[mx_idx]\n",
    "print(\"SVR Train Score from max Test Score: \", train_mx_test, \"\\n\",\n",
    "      \"Max Test Score: \", mx_test, \"\\n\",\n",
    "     \"Achieved with {} features out of 15\".format(mx_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN = 0.5494\n",
    "#### TEST = 0.4087"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM FOREST (+clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips = np.arange(100,170,10).tolist()\n",
    "train_scores_rf = []\n",
    "test_scores_rf = []\n",
    "for clip in clips:\n",
    "    X_train = df_train_1.drop(columns=[\"ID\",\"Cycle\",\"RUL\",\"operarional_setting_1\",\"operarional_setting_2\"], axis=1)\n",
    "    y_train_clip = df_train_1[\"RUL\"].clip(upper=clip)\n",
    "\n",
    "    df_test_1_red = df_test_1.groupby(\"ID\").last().reset_index()\n",
    "    X_test = df_test_1_red.drop(columns=[\"ID\",\"Cycle\",\"operarional_setting_1\",\"operarional_setting_2\"], axis=1)\n",
    "    y_test = df_rul_1\n",
    "\n",
    "    regr = RandomForestRegressor()\n",
    "    rf_random_clip = RandomizedSearchCV(estimator=regr, param_distributions=random_grid, random_state=42)\n",
    "    rf_random_clip.fit(X_train, y_train_clip)\n",
    "    n_estimators = list(rf_random_clip.best_params_.values())[0]\n",
    "    max_depth = list(rf_random_clip.best_params_.values())[1]\n",
    "    hyper_regr = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth)\n",
    "    hyper_regr.fit(X_train, y_train_clip)\n",
    "    rul_train_pred_rf = hyper_regr.predict(X_train)\n",
    "    r2_tr = r2_score(y_train_clip, rul_train_pred_rf)\n",
    "    train_scores_rf.append(r2_tr)\n",
    "    print(\" TRAIN SCORE WITH {} upper clipped RUL: \".format(clip), r2_score(y_train_clip, rul_train_pred_rf))\n",
    "    \n",
    "    rul_test_pred_rf = hyper_regr.predict(X_test)\n",
    "    r2_ts = r2_score(y_test, rul_test_pred_rf)\n",
    "    test_scores_rf.append(r2_ts)\n",
    "    print(\" TEST SCORE WITH {} upper clipped RUL: \".format(clip), r2_score(y_test, rul_test_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,len(column)),train_scores,label=\"train scores\")\n",
    "plt.plot(range(0,len(column)), test_scores, label=\"test scores\")\n",
    "plt.legend()\n",
    "mx_test = max(test_scores)\n",
    "mx_idx = test_scores.index(mx_test)\n",
    "train_mx_test = train_scores[mx_idx]\n",
    "print(\"SVR Train Score from max Test Score: \", train_mx_test, \"\\n\",\n",
    "      \"Max Test Score: \", mx_test, \"\\n\",\n",
    "     \"Achieved with {} features out of 15\".format(mx_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN = 0.5494\n",
    "#### TEST = 0.4087"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR (+y_CLIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips = np.arange(100,170,5).tolist()\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for clip in clips:\n",
    "    X_train = df_train_1.drop(columns=[\"ID\",\"Cycle\",\"RUL\",\"operarional_setting_1\",\"operarional_setting_2\"], axis=1)\n",
    "    y_train_clip = df_train_1[\"RUL\"].clip(upper=clip)\n",
    "\n",
    "    df_test_1_red = df_test_1.groupby(\"ID\").last().reset_index()\n",
    "    X_test = df_test_1_red.drop(columns=[\"ID\",\"Cycle\",\"operarional_setting_1\",\"operarional_setting_2\"], axis=1)\n",
    "    y_test = df_rul_1\n",
    "\n",
    "    svr = SVR(kernel=\"linear\")\n",
    "    svr.fit(X_train, y_train_clip)\n",
    "    preds_train = svr.predict(X_train)\n",
    "    r2_tr = r2_score(y_train_clip, preds_train)\n",
    "    train_scores.append(r2_tr)\n",
    "    print(\" TRAIN SCORE WITH {} upper clipped RUL: \".format(clip), r2_score(y_train_clip, preds_train))\n",
    "    \n",
    "    preds_test = svr.predict(X_test)\n",
    "    r2_ts = r2_score(y_test, preds_test)\n",
    "    test_scores.append(r2_ts)\n",
    "    print(\" TEST SCORE WITH {} upper clipped RUL: \".format(clip), r2_score(y_test, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,len(column)),train_scores,label=\"train scores\")\n",
    "plt.plot(range(0,len(column)), test_scores, label=\"test scores\")\n",
    "plt.legend()\n",
    "mx_test = max(test_scores)\n",
    "mx_idx = test_scores.index(mx_test)\n",
    "train_mx_test = train_scores[mx_idx]\n",
    "print(\"SVR Train Score from max Test Score: \", train_mx_test, \"\\n\",\n",
    "      \"Max Test Score: \", mx_test, \"\\n\",\n",
    "     \"Achieved with {} features out of 15\".format(mx_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN = 0.5494\n",
    "#### TEST = 0.4087"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIN_MAX_SCALER + TOP_FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearRegression (+MinMax + Top_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = slopes_df[\"columns\"].values.tolist()\n",
    "column=[]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for col in columns:\n",
    "    column.append(col)\n",
    "    \n",
    "    df = df_train_1[[\"ID\",\"Cycle\"]+column]\n",
    "    X_train = df.drop(columns=[\"ID\",\"Cycle\"], axis=1)\n",
    "    \n",
    "    y_train = df_train_1[\"RUL\"]\n",
    "    df_test = df_test_1[[\"ID\", \"Cycle\"]+column]\n",
    "    df_test_red = df_test.groupby(\"ID\").last().reset_index()\n",
    "    X_test = df_test_red.drop(columns=[\"ID\",\"Cycle\"], axis=1)\n",
    "    y_test = df_rul_1\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scal = scaler.transform(X_train)\n",
    "    X_test_scal = scaler.transform(X_test)\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train_scal, y_train)\n",
    "    preds_train = lr.predict(X_train_scal)\n",
    "    r2_tr = r2_score(y_train, preds_train)\n",
    "    train_scores.append(r2_tr)\n",
    "    print(\" TRAIN SCORE WITH {} top features: \".format(len(column)), r2_score(y_train, preds_train))\n",
    "    \n",
    "    preds_test = lr.predict(X_test_scal)\n",
    "    r2_ts = r2_score(y_test, preds_test)\n",
    "    test_scores.append(r2_ts)\n",
    "    print(\" TEST SCORE WITH {} top features: \".format(len(column)), r2_score(y_test, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,len(column)),train_scores,label=\"train scores\")\n",
    "plt.plot(range(0,len(column)), test_scores, label=\"test scores\")\n",
    "plt.legend()\n",
    "mx_test = max(test_scores)\n",
    "mx_idx = test_scores.index(mx_test)\n",
    "train_mx_test = train_scores[mx_idx]\n",
    "print(\"SVR Train Score from max Test Score: \", train_mx_test, \"\\n\",\n",
    "      \"Max Test Score: \", mx_test, \"\\n\",\n",
    "     \"Achieved with {} features out of 15\".format(mx_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN = 0.5494\n",
    "#### TEST = 0.4087"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RanfomForest (+MinMax + Top_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = slopes_df[\"columns\"].values.tolist()\n",
    "column=[]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for col in columns:\n",
    "    column.append(col)\n",
    "    \n",
    "    df = df_train_1[[\"ID\",\"Cycle\"]+column]\n",
    "    X_train = df.drop(columns=[\"ID\",\"Cycle\"], axis=1)\n",
    "    y_train = df_train_1[\"RUL\"]\n",
    "    df_test = df_test_1[[\"ID\", \"Cycle\"]+column]\n",
    "    df_test_red = df_test.groupby(\"ID\").last().reset_index()\n",
    "    X_test = df_test_red.drop(columns=[\"ID\",\"Cycle\"], axis=1)\n",
    "    y_test = df_rul_1\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scal = scaler.transform(X_train)\n",
    "    X_test_scal = scaler.transform(X_test)\n",
    "    \n",
    "    regr = RandomForestRegressor()\n",
    "    rf_random = RandomizedSearchCV(estimator=regr, param_distributions=random_grid, random_state=42)\n",
    "    rf_random.fit(X_train_scal, y_train)\n",
    "    \n",
    "    n_estimators = list(rf_random.best_params_.values())[0]\n",
    "    max_depth = list(rf_random.best_params_.values())[1]\n",
    "    \n",
    "    hyper_regr = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth)\n",
    "    hyper_regr.fit(X_train_scal, y_train)\n",
    "    \n",
    "    rul_train_pred_rf = hyper_regr.predict(X_train_scal)\n",
    "    r2_tr = r2_score(y_train, rul_train_pred_rf)\n",
    "    train_scores.append(r2_tr)\n",
    "    print(\" TRAIN SCORE WITH {} top features: \".format(len(column)), r2_score(y_train, rul_train_pred_rf))\n",
    "    \n",
    "    rul_test_pred_rf = hyper_regr.predict(X_test_scal)\n",
    "    r2_ts = r2_score(y_test, rul_test_pred_rf)\n",
    "    test_scores.append(r2_ts)\n",
    "    print(\" TEST SCORE WITH {} top features: \".format(len(column)), r2_score(y_test, rul_test_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,len(column)),train_scores,label=\"train scores\")\n",
    "plt.plot(range(0,len(column)), test_scores, label=\"test scores\")\n",
    "plt.legend()\n",
    "mx_test = max(test_scores)\n",
    "mx_idx = test_scores.index(mx_test)\n",
    "train_mx_test = train_scores[mx_idx]\n",
    "print(\"SVR Train Score from max Test Score: \", train_mx_test, \"\\n\",\n",
    "      \"Max Test Score: \", mx_test, \"\\n\",\n",
    "     \"Achieved with {} features out of 15\".format(mx_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN = 0.5494\n",
    "#### TEST = 0.4087"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR (+MinMax + top_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = slopes_df[\"columns\"].values.tolist()\n",
    "column=[]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for col in columns:\n",
    "    column.append(col)\n",
    "    \n",
    "    df = df_train_1[[\"ID\",\"Cycle\"]+column]\n",
    "    X_train = df.drop(columns=[\"ID\",\"Cycle\"], axis=1)\n",
    "    \n",
    "    y_train = df_train_1[\"RUL\"]\n",
    "    df_test = df_test_1[[\"ID\", \"Cycle\"]+column]\n",
    "    df_test_red = df_test.groupby(\"ID\").last().reset_index()\n",
    "    X_test = df_test_red.drop(columns=[\"ID\",\"Cycle\"], axis=1)\n",
    "    y_test = df_rul_1\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scal = scaler.transform(X_train)\n",
    "    X_test_scal = scaler.transform(X_test)\n",
    "    \n",
    "    svr = SVR(kernel=\"linear\")\n",
    "    svr.fit(X_train_scal, y_train)\n",
    "    preds_train = svr.predict(X_train_scal)\n",
    "    r2_tr = r2_score(y_train, preds_train)\n",
    "    train_scores.append(r2_tr)\n",
    "    print(\" TRAIN SCORE WITH {} top features: \".format(len(column)), r2_score(y_train, preds_train))\n",
    "    \n",
    "    preds_test = svr.predict(X_test_scal)\n",
    "    r2_ts = r2_score(y_test, preds_test)\n",
    "    test_scores.append(r2_ts)\n",
    "    print(\" TEST SCORE WITH {} top features: \".format(len(column)), r2_score(y_test, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,len(column)),train_scores,label=\"train scores\")\n",
    "plt.plot(range(0,len(column)), test_scores, label=\"test scores\")\n",
    "plt.legend()\n",
    "mx_test = max(test_scores)\n",
    "mx_idx = test_scores.index(mx_test)\n",
    "train_mx_test = train_scores[mx_idx]\n",
    "print(\"SVR Train Score from max Test Score: \", train_mx_test, \"\\n\",\n",
    "      \"Max Test Score: \", mx_test, \"\\n\",\n",
    "     \"Achieved with {} features out of 15\".format(mx_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN = 0.5494\n",
    "#### TEST = 0.4087"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIN_MAX_SCALER + y_Clip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression (+minMax + y_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips = np.arange(100,170,5).tolist()\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for clip in clips:\n",
    "    X_train = df_train_1.drop(columns=[\"ID\",\"Cycle\",\"RUL\",\"operarional_setting_1\",\"operarional_setting_2\"], axis=1)\n",
    "    y_train_clip = df_train_1[\"RUL\"].clip(upper=clip)\n",
    "\n",
    "    df_test_1_red = df_test_1.groupby(\"ID\").last().reset_index()\n",
    "    X_test = df_test_1_red.drop(columns=[\"ID\",\"Cycle\",\"operarional_setting_1\",\"operarional_setting_2\"], axis=1)\n",
    "    y_test = df_rul_1\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scal = scaler.transform(X_train)\n",
    "    X_test_scal = scaler.transform(X_test)\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train_scal, y_train_clip)\n",
    "    preds_train = lr.predict(X_train_scal)\n",
    "    r2_tr = r2_score(y_train_clip, preds_train)\n",
    "    train_scores.append(r2_tr)\n",
    "    print(\" TRAIN SCORE WITH {} upper clipped RUL: \".format(clip), r2_score(y_train_clip, preds_train))\n",
    "    \n",
    "    preds_test = lr.predict(X_test_scal)\n",
    "    r2_ts = r2_score(y_test, preds_test)\n",
    "    test_scores.append(r2_ts)\n",
    "    print(\" TEST SCORE WITH {} upper clipped RUL: \".format(clip), r2_score(y_test, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,len(column)),train_scores,label=\"train scores\")\n",
    "plt.plot(range(0,len(column)), test_scores, label=\"test scores\")\n",
    "plt.legend()\n",
    "mx_test = max(test_scores)\n",
    "mx_idx = test_scores.index(mx_test)\n",
    "train_mx_test = train_scores[mx_idx]\n",
    "print(\"SVR Train Score from max Test Score: \", train_mx_test, \"\\n\",\n",
    "      \"Max Test Score: \", mx_test, \"\\n\",\n",
    "     \"Achieved with {} features out of 15\".format(mx_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN = 0.5494\n",
    "#### TEST = 0.4087"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest (+minMax + y_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips = np.arange(100,170,10).tolist()\n",
    "train_scores_rf = []\n",
    "test_scores_rf = []\n",
    "for clip in clips:\n",
    "    X_train = df_train_1.drop(columns=[\"ID\",\"Cycle\",\"RUL\",\"operarional_setting_1\",\"operarional_setting_2\"], axis=1)\n",
    "    y_train_clip = df_train_1[\"RUL\"].clip(upper=clip)\n",
    "\n",
    "    df_test_1_red = df_test_1.groupby(\"ID\").last().reset_index()\n",
    "    X_test = df_test_1_red.drop(columns=[\"ID\",\"Cycle\",\"operarional_setting_1\",\"operarional_setting_2\"], axis=1)\n",
    "    y_test = df_rul_1\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scal = scaler.transform(X_train)\n",
    "    X_test_scal = scaler.transform(X_test)\n",
    "    \n",
    "    regr = RandomForestRegressor()\n",
    "    rf_random_clip = RandomizedSearchCV(estimator=regr, param_distributions=random_grid, random_state=42)\n",
    "    rf_random_clip.fit(X_train_scal, y_train_clip)\n",
    "    n_estimators = list(rf_random_clip.best_params_.values())[0]\n",
    "    max_depth = list(rf_random_clip.best_params_.values())[1]\n",
    "    hyper_regr = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth)\n",
    "    hyper_regr.fit(X_train_scal, y_train_clip)\n",
    "    \n",
    "    rul_train_pred_rf = hyper_regr.predict(X_train_scal)\n",
    "    r2_tr = r2_score(y_train_clip, rul_train_pred_rf)\n",
    "    train_scores_rf.append(r2_tr)\n",
    "    print(\" TRAIN SCORE WITH {} upper clipped RUL: \".format(clip), r2_score(y_train_clip, rul_train_pred_rf))\n",
    "    \n",
    "    rul_test_pred_rf = hyper_regr.predict(X_test_scal)\n",
    "    r2_ts = r2_score(y_test, rul_test_pred_rf)\n",
    "    test_scores_rf.append(r2_ts)\n",
    "    print(\" TEST SCORE WITH {} upper clipped RUL: \".format(clip), r2_score(y_test, rul_test_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,len(column)),train_scores,label=\"train scores\")\n",
    "plt.plot(range(0,len(column)), test_scores, label=\"test scores\")\n",
    "plt.legend()\n",
    "mx_test = max(test_scores)\n",
    "mx_idx = test_scores.index(mx_test)\n",
    "train_mx_test = train_scores[mx_idx]\n",
    "print(\"SVR Train Score from max Test Score: \", train_mx_test, \"\\n\",\n",
    "      \"Max Test Score: \", mx_test, \"\\n\",\n",
    "     \"Achieved with {} features out of 15\".format(mx_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN = 0.5494\n",
    "#### TEST = 0.4087"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR (+minMax + y_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips = np.arange(100,170,5).tolist()\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for clip in clips:\n",
    "    X_train = df_train_1.drop(columns=[\"ID\",\"Cycle\",\"RUL\",\"operarional_setting_1\",\"operarional_setting_2\"], axis=1)\n",
    "    y_train_clip = df_train_1[\"RUL\"].clip(upper=clip)\n",
    "\n",
    "    df_test_1_red = df_test_1.groupby(\"ID\").last().reset_index()\n",
    "    X_test = df_test_1_red.drop(columns=[\"ID\",\"Cycle\",\"operarional_setting_1\",\"operarional_setting_2\"], axis=1)\n",
    "    y_test = df_rul_1\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scal = scaler.transform(X_train)\n",
    "    X_test_scal = scaler.transform(X_test)\n",
    "    \n",
    "    svr = SVR(kernel=\"linear\")\n",
    "    svr.fit(X_train_scal, y_train_clip)\n",
    "    preds_train = svr.predict(X_train_scal)\n",
    "    r2_tr = r2_score(y_train_clip, preds_train)\n",
    "    train_scores.append(r2_tr)\n",
    "    print(\" TRAIN SCORE WITH {} upper clipped RUL: \".format(clip), r2_score(y_train_clip, preds_train))\n",
    "    \n",
    "    preds_test = svr.predict(X_test_scal)\n",
    "    r2_ts = r2_score(y_test, preds_test)\n",
    "    test_scores.append(r2_ts)\n",
    "    print(\" TEST SCORE WITH {} upper clipped RUL: \".format(clip), r2_score(y_test, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,len(column)),train_scores,label=\"train scores\")\n",
    "plt.plot(range(0,len(column)), test_scores, label=\"test scores\")\n",
    "plt.legend()\n",
    "mx_test = max(test_scores)\n",
    "mx_idx = test_scores.index(mx_test)\n",
    "train_mx_test = train_scores[mx_idx]\n",
    "print(\"SVR Train Score from max Test Score: \", train_mx_test, \"\\n\",\n",
    "      \"Max Test Score: \", mx_test, \"\\n\",\n",
    "     \"Achieved with {} features out of 15\".format(mx_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN = 0.5494\n",
    "#### TEST = 0.4087"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOP_FEATURES + y_clip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearRegression (+top_feat + y_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = slopes_df[\"columns\"].values.tolist()\n",
    "column=[]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for col in columns:\n",
    "    column.append(col)\n",
    "    clips = np.arange(100,170,5).tolist()\n",
    "    for clip in clips:\n",
    "        df = df_train_1[[\"ID\",\"Cycle\"]+column]\n",
    "        \n",
    "        X_train = df.drop(columns=[\"ID\",\"Cycle\"], axis=1)\n",
    "        y_train_clip = df_train_1[\"RUL\"].clip(upper=clip)\n",
    "        \n",
    "        df_test = df_test_1[[\"ID\", \"Cycle\"]+column]\n",
    "        df_test_red = df_test.groupby(\"ID\").last().reset_index()\n",
    "        X_test = df_test_red.drop(columns=[\"ID\",\"Cycle\"], axis=1)\n",
    "        y_test = df_rul_1\n",
    "\n",
    "\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(X_train_scal, y_train)\n",
    "        preds_train = lr.predict(X_train_scal)\n",
    "        r2_tr = r2_score(y_train, preds_train)\n",
    "        train_scores.append(r2_tr)\n",
    "        print(\" TRAIN SCORE WITH {} top features: \".format(len(column)), r2_score(y_train, preds_train))\n",
    "\n",
    "        preds_test = lr.predict(X_test_scal)\n",
    "        r2_ts = r2_score(y_test, preds_test)\n",
    "        test_scores.append(r2_ts)\n",
    "        print(\" TEST SCORE WITH {} top features: \".format(len(column)), r2_score(y_test, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips = np.arange(100,170,5).tolist()\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for clip in clips:\n",
    "    X_train = df_train_1.drop(columns=[\"ID\",\"Cycle\",\"RUL\",\"operarional_setting_1\",\"operarional_setting_2\"], axis=1)\n",
    "    y_train_clip = df_train_1[\"RUL\"].clip(upper=clip)\n",
    "\n",
    "    df_test_1_red = df_test_1.groupby(\"ID\").last().reset_index()\n",
    "    X_test = df_test_1_red.drop(columns=[\"ID\",\"Cycle\",\"operarional_setting_1\",\"operarional_setting_2\"], axis=1)\n",
    "    y_test = df_rul_1\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scal = scaler.transform(X_train)\n",
    "    X_test_scal = scaler.transform(X_test)\n",
    "    \n",
    "    svr = SVR(kernel=\"linear\")\n",
    "    svr.fit(X_train_scal, y_train_clip)\n",
    "    preds_train = svr.predict(X_train_scal)\n",
    "    r2_tr = r2_score(y_train_clip, preds_train)\n",
    "    train_scores.append(r2_tr)\n",
    "    print(\" TRAIN SCORE WITH {} upper clipped RUL: \".format(clip), r2_score(y_train_clip, preds_train))\n",
    "    \n",
    "    preds_test = svr.predict(X_test_scal)\n",
    "    r2_ts = r2_score(y_test, preds_test)\n",
    "    test_scores.append(r2_ts)\n",
    "    print(\" TEST SCORE WITH {} upper clipped RUL: \".format(clip), r2_score(y_test, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "524658468-*251\n",
    "Ã§485\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No great changes by using MinMax Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clip RUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = df_train_1.drop(columns=[\"ID\",\"Cycle\",\"RUL\"], axis=1)\n",
    "y_train_1clip = df_train_1[\"RUL\"].clip(upper=125)\n",
    "\n",
    "df_test_1_red = df_test_1.groupby(\"ID\").last().reset_index()\n",
    "X_test1 = df_test_1_red.drop(columns=[\"ID\",\"Cycle\"], axis=1)\n",
    "y_test = df_rul_1\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train1, y_train_1clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train_clip = lr.predict(X_train1)\n",
    "print(\"TRAIN SCORES - - - - \", \"\\n\",\n",
    "    \"MAE: \", mean_absolute_error(y_train_1clip,preds_train_clip), \"\\n\",\n",
    "      \"R2 score: \", r2_score(y_train_1clip, preds_train_clip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test_clip = lr.predict(X_test1)\n",
    "print(\"TRAIN SCORES - - - - \", \"\\n\",\n",
    "    \"MAE: \", mean_absolute_error(y_test,preds_test_clip), \"\\n\",\n",
    "      \"R2 score: \", r2_score(y_test, preds_test_clip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips = np.arange(100,150,5).tolist()\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for clip in clips:\n",
    "    X_train = df_train_1.drop(columns=[\"ID\",\"Cycle\",\"RUL\"], axis=1)\n",
    "    y_train_clip = df_train_1[\"RUL\"].clip(upper=clip)\n",
    "\n",
    "    df_test_1_red = df_test_1.groupby(\"ID\").last().reset_index()\n",
    "    X_test = df_test_1_red.drop(columns=[\"ID\",\"Cycle\"], axis=1)\n",
    "    y_test = df_rul_1\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train_clip)\n",
    "    preds_train = lr.predict(X_train)\n",
    "    r2_tr = r2_score(y_train_clip, preds_train)\n",
    "    train_scores.append(r2_tr)\n",
    "    print(\" TRAIN SCORE WITH {} upper clipped RUL: \".format(clip), r2_score(y_train_clip, preds_train))\n",
    "    \n",
    "    preds_test = lr.predict(X_test)\n",
    "    r2_ts = r2_score(y_test, preds_test)\n",
    "    test_scores.append(r2_ts)\n",
    "    print(\" TEST SCORE WITH {} upper clipped RUL: \".format(clip), r2_score(y_test, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,len(clips)),train_scores,label=\"train scores\")\n",
    "plt.plot(range(0,len(clips)), test_scores, label=\"test scores\")\n",
    "plt.legend()\n",
    "mx_test = max(test_scores)\n",
    "mx_idx = test_scores.index(mx_test)\n",
    "train_mx_test = train_scores[mx_idx]\n",
    "print(\"Train Score from max Test Score: \", train_mx_test, \"\\n\",\n",
    "      \"Max Test Score: \", mx_test, \"\\n\",\n",
    "     \"Achieved with {} upper clipped RUL\".format(clip))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA with top slope features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_features_df = slopes_df.sort_values(\"slope\", ascending=False).head(5)\n",
    "top_10_features = top_10_features_df[\"columns\"].values.tolist()\n",
    "top_10_df = df_train_1[top_10_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(top_10_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_pca = pca.transform()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
